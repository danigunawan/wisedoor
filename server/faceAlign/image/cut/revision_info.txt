arguments: ./faceAlign/app.py
--------------------
tensorflow version: 1.7.0
--------------------
git hash: b'4782d6a235359714fd2983b3c7d59c449a5eb309'
--------------------
b'diff --git a/client/src/App.vue b/client/src/App.vue\nindex 42833f7..9073c75 100644\n--- a/client/src/App.vue\n+++ b/client/src/App.vue\n@@ -30,4 +30,6 @@ export default {\n   -moz-osx-font-smoothing: grayscale;\n   color: #2c3e50;\n }\n+\n+\n </style>\ndiff --git a/client/src/Main.vue b/client/src/Main.vue\nindex 158f3a1..9f1013d 100644\n--- a/client/src/Main.vue\n+++ b/client/src/Main.vue\n@@ -4,7 +4,7 @@\n     <div class="container">\n       <div class="row justify-content-center">\n         <div class="col-12 col-lg-2">\n-          <h5 class="mb-3 text-center">\xe6\x82\xa8\xe7\x9a\x84\xe8\xa8\xad\xe5\x82\x99\xe5\x88\x97\xe8\xa1\xa8</h5>\n+          <h5 class="mb-3 text-center big-font-size">\xe6\x82\xa8\xe7\x9a\x84\xe8\xa8\xad\xe5\x82\x99\xe5\x88\x97\xe8\xa1\xa8</h5>\n           <equipment-list ref="equipmentList"></equipment-list>\n         </div>\n         <div class="col-12 col-lg-8 row">\n@@ -87,12 +87,15 @@ export default {\n \n     async CheckModelIsTrain(equipmentName){\n       const timerId = setInterval(checkIsTrain,500)\n-\n+      const equipmentList = this.$refs.equipmentList \n+      let isAlert = false\n       async function checkIsTrain() {\n         const isTrained = (await TrainService.checkModelIsOk(equipmentName)).data\n-        if(isTrained){\n+        if(isTrained && !isAlert){\n+          isAlert = true\n+          equipmentList.UpdateEquipmentList()\n           alert("\xe8\x87\x89\xe5\xad\x94\xe8\x99\x95\xe7\x90\x86\xe5\xb7\xb2\xe5\xae\x8c\xe6\x88\x90")\n-          clearInterval(timerId);\n+          clearInterval(timerId)\n         }\n       }\n     },\n@@ -113,4 +116,8 @@ export default {\n   text-align: center;\n }\n \n+.big-font-size {\n+  font-size: 25px;\n+}\n+\n </style>\ndiff --git a/client/src/components/AddFaceModal.vue b/client/src/components/AddFaceModal.vue\nindex 44f9035..5b45594 100644\n--- a/client/src/components/AddFaceModal.vue\n+++ b/client/src/components/AddFaceModal.vue\n@@ -1,23 +1,23 @@\n <template>\n \n <div id="add-face-modal" class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-labelledby="mySmallModalLabel" aria-hidden="true">\n-  <div class="modal-dialog modal-sm">\n+  <div class="modal-dialog">\n     <div class="modal-content">\n       <div class="modal-header">\n-        <h5 class="modal-title">\xe6\x96\xb0\xe5\xa2\x9e\xe8\x87\x89\xe5\xad\x94</h5>\n+        <h5 class="modal-title add-face-title-size">\xe6\x96\xb0\xe5\xa2\x9e\xe8\x87\x89\xe5\xad\x94</h5>\n         <button type="button" class="close" data-dismiss="modal" aria-label="Close">\n           <span aria-hidden="true">&times;</span>\n         </button>\n       </div>\n       <div class="modal-body">\n-        <p>\xe8\xab\x8b\xe9\x81\xb8\xe6\x93\x87\xe4\xb8\x80\xe5\x80\x8b\xe6\x82\xa8\xe7\x9a\x84\xe8\xa8\xad\xe5\x82\x99</p>\n+        <p class="prompt-text-size">\xe8\xab\x8b\xe9\x81\xb8\xe6\x93\x87\xe4\xb8\x80\xe5\x80\x8b\xe6\x82\xa8\xe7\x9a\x84\xe8\xa8\xad\xe5\x82\x99</p>\n         <div class="equipment-choose-button mb-4" v-for="(equipment,index) in equipments">\n-          <button type="button" class="btn btn-success" @click="chooseEquipment(index)">{{ equipment.Name }}</button>\n+          <button type="button" class="btn btn-outline-dark equipment-button-size" @click="chooseEquipment(index)">{{ equipment.Name }}</button>\n           <img src="../assets/sign-check-icon.png" v-if="choosed[index]" width="30px" alt="">\n         </div>\n-        <p>\xe8\xab\x8b\xe8\xbc\xb8\xe5\x85\xa5\xe8\x87\x89\xe5\xad\x94\xe5\x90\x8d\xe7\xa8\xb1</p>\n+        <p class="prompt-text-size">\xe8\xab\x8b\xe8\xbc\xb8\xe5\x85\xa5\xe8\x87\x89\xe5\xad\x94\xe5\x90\x8d\xe7\xa8\xb1</p>\n         <div class="form-group">\n-          <input type="text" class="form-control" v-model="faceName" placeholder="\xe8\x87\x89\xe5\xad\x94\xe5\x90\x8d\xe7\xa8\xb1">\n+          <input type="text" class="form-control input-face-name-size" v-model="faceName" placeholder="\xe8\x87\x89\xe5\xad\x94\xe5\x90\x8d\xe7\xa8\xb1">\n         </div>\n       </div>\n       <div class="modal-footer">\n@@ -82,7 +82,25 @@ export default {\n </script>\n \n <style>\n+\n+.add-face-title-size {\n+  font-size: 26px;\n+}\n+\n .equipment-choose-button {\n   display: block;\n }\n+\n+.prompt-text-size {\n+  font-size: 22px;\n+}\n+\n+.input-face-name-size {\n+  font-size: 22px;\n+}\n+\n+.equipment-button-size {\n+  font-size: 22px;\n+}\n+\n </style>\ndiff --git a/client/src/components/EquipmentList.vue b/client/src/components/EquipmentList.vue\nindex 4cb6a7e..6396823 100644\n--- a/client/src/components/EquipmentList.vue\n+++ b/client/src/components/EquipmentList.vue\n@@ -2,13 +2,13 @@\n   <div id="equipment-list">\n     <div class="card" v-for="equipment in equipments">\n       <div class="card-header">\n-        <button class="btn btn-success" data-toggle="collapse" :data-target="\'#equipment\' + equipment.Id" aria-expanded="true" :aria-controls="\'#equipment\' + equipment.Id">\n+        <button class="btn btn-outline-dark equipment-button" data-toggle="collapse" :data-target="\'#equipment\' + equipment.Id" aria-expanded="true" :aria-controls="\'#equipment\' + equipment.Id">\n           {{equipment.Name}}\n          </button>\n       </div>\n       <div :id="\'equipment\' + equipment.Id" class="collapse" aria-labelledby="headingOne" data-parent="#equipment-list">\n         <div class="card-body">\n-          <button type="button" class="btn btn-outline-info col-12 mb-2"  v-for="face in equipment.Face">{{face.Name}}</button>\n+          <button type="button" class="face-button btn btn-outline-primary col-12 mb-2"  v-for="face in equipment.Face">{{face.Name}}</button>\n         </div>\n       </div>\n     </div>\n@@ -49,4 +49,13 @@ export default {\n \n <style>\n \n+.equipment-button {\n+  font-size: 20px;\n+}\n+\n+.face-button {\n+  font-size: 22px;\n+  font-weight: bold;\n+}\n+\n </style>\ndiff --git a/client/src/components/Headers.vue b/client/src/components/Headers.vue\nindex 7f1d98a..8309aa3 100644\n--- a/client/src/components/Headers.vue\n+++ b/client/src/components/Headers.vue\n@@ -1,6 +1,6 @@\n <template>\n   <div id="header">\n-    <nav class="navbar navbar-expand-lg navbar-light bg-light mb-4">\n+    <nav class="navbar navbar-expand-lg navbar-dark bg-dark mb-4">\n         <a class="navbar-brand" href="#">\xe6\x99\xba\xe6\x85\xa7\xe9\x96\x80\xe9\x8e\x96</a>\n         <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent">\n           <span class="navbar-toggler-icon"></span>\n@@ -9,6 +9,8 @@\n             <ul class="navbar-nav ml-auto">\n                 <li class="nav-item">\n                     <a class="nav-link loginout-button" href="#" data-toggle="modal" data-target="#login-modal">{{ userName }}</a>\n+                </li>\n+                <li>\n                     <a class="nav-link loginout-button" href="#" @click="logout()" v-if="isLogin">\xe7\x99\xbb\xe5\x87\xba</a>\n                 </li>\n             </ul>\n@@ -51,7 +53,4 @@ export default {\n   box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.1);\n }\n \n-.loginout-button {\n-  display: inline-block;\n-}\n </style>\ndiff --git a/client/src/components/TrainMenu.vue b/client/src/components/TrainMenu.vue\nindex 5c33ec9..8d56324 100644\n--- a/client/src/components/TrainMenu.vue\n+++ b/client/src/components/TrainMenu.vue\n@@ -1,9 +1,9 @@\n <template>\n   <div id="train-menu">\n     <div class="row justify-content-around">\n-      <button class="mb-4 col-5 col-lg-12 btn btn-outline-info" data-toggle="modal" data-target="#add-face-modal">\xe6\x96\xb0\xe5\xa2\x9e\xe8\x87\x89\xe5\xad\x94</button>\n-      <button class="mb-4 col-5 col-lg-12 btn btn-outline-info" data-toggle="modal" data-target="#register-equipment-modal">\xe6\x96\xb0\xe5\xa2\x9e\xe8\xa8\xad\xe5\x82\x99</button>\n-      <button class="mb-4 col-5 col-lg-12 btn btn-outline-info">\xe7\x99\xbb\xe5\x85\xa5\xe7\xb4\x80\xe9\x8c\x84</button>\n+      <button class="mb-4 col-5 col-lg-12 btn btn-outline-dark train-menu-button" data-toggle="modal" data-target="#add-face-modal">\xe6\x96\xb0\xe5\xa2\x9e\xe8\x87\x89\xe5\xad\x94</button>\n+      <button class="mb-4 col-5 col-lg-12 btn btn-outline-dark train-menu-button" data-toggle="modal" data-target="#register-equipment-modal">\xe6\x96\xb0\xe5\xa2\x9e\xe8\xa8\xad\xe5\x82\x99</button>\n+      <button class="mb-4 col-5 col-lg-12 btn btn-outline-dark train-menu-button">\xe7\x99\xbb\xe5\x85\xa5\xe7\xb4\x80\xe9\x8c\x84</button>\n     </div>\n   </div>\n </template>\n@@ -32,4 +32,9 @@ export default {\n \n <style>\n \n+.train-menu-button {\n+  font-size: 25px;\n+  font-weight: bold;\n+}\n+\n </style>\ndiff --git a/client/src/components/UploadFaceProgress.vue b/client/src/components/UploadFaceProgress.vue\nindex 9ef7c04..1966919 100644\n--- a/client/src/components/UploadFaceProgress.vue\n+++ b/client/src/components/UploadFaceProgress.vue\n@@ -1,7 +1,7 @@\n <template>\n   <div id="upload-face-progress" >\n     <div class="row justify-content-end">\n-      <p class="col-12 text-right">\xe4\xb8\x8a\xe5\x82\xb3\xe9\x80\xb2\xe5\xba\xa6 {{percentage}} / 100</p>\n+      <p id="text-progress" class="col-12 text-right">\xe4\xb8\x8a\xe5\x82\xb3\xe9\x80\xb2\xe5\xba\xa6 {{percentage}} / 100</p>\n     </div>\n     <div class="progress">\n       <div class="progress-bar bg-success" role="progressbar" :style="{ width: percentage + \'%\' }" aria-valuenow="25" aria-valuemin="0" aria-valuemax="100"></div>\n@@ -31,6 +31,11 @@ export default {\n </script>\n \n <style>\n+\n+#text-progress {\n+  font-size: 22px;\n+}\n+\n .text-right {\n   text-align: right;\n }\ndiff --git a/device/.gitignore b/device/.gitignore\nnew file mode 100644\nindex 0000000..f2a723b\n--- /dev/null\n+++ b/device/.gitignore\n@@ -0,0 +1 @@\n+*.pkl\n\\ No newline at end of file\ndiff --git a/device/Classify.py b/device/Classify.py\nindex ff947c1..0094040 100644\n--- a/device/Classify.py\n+++ b/device/Classify.py\n@@ -1,27 +1,3 @@\n-"""An example of how to use your own dataset to train a classifier that recognizes people.\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -36,62 +12,38 @@ import math\n import pickle\n from sklearn.svm import SVC\n import time\n+\n model_path  = "./models/20170512-110547.pb"\n-test_classifier_path = "./test.pkl"\n \n-tensorflow_graph = tf.Graph()\n-sess = tf.Session()\n-with tensorflow_graph.as_default():\n-    print(\'Loading feature extraction model\')\n-    facenet.load_model(model_path)\n-    \n-    # Get input and output tensors\n-    images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n-    embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n-    phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n-    embedding_size =  embeddings.get_shape()[1]\n+class Classify():\n+    def __init__(self):\n+        tensorflow_graph = tf.Graph()\n+        with tensorflow_graph.as_default():\n+            facenet.load_model(model_path)\n+            self.images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n+            self.embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n+            self.phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n+            self.embedding_size =  self.embeddings.get_shape()[1]\n+        self.sess = tf.Session(graph=tensorflow_graph)\n+\n+    def classify_image(self,input_file_path,model_object):\n+        np.random.seed(seed=666)\n \n-    print(\'Testing classifier\')\n-    classifier_filename_exp = os.path.expanduser(test_classifier_path)\n+        model = model_object.get_model()\n+        class_names = model_object.get_class_names()\n \n-    with open(classifier_filename_exp, \'rb\') as infile:\n-        (model, class_names) = pickle.load(infile)\n-    print(\'Loaded classifier model from file "%s"\' % classifier_filename_exp)\n-    \n-with tf.Session(graph=tensorflow_graph) as sess:\n-    def reload_model():\n-        print(\'Testing classifier\')\n-        classifier_filename_exp = os.path.expanduser(test_classifier_path)\n+        nrof_images = 1\n+        emb_array = np.zeros((nrof_images,  self.embedding_size))\n \n-        with open(classifier_filename_exp, \'rb\') as infile:\n-            (model, class_names) = pickle.load(infile)\n-        print(\'Loaded classifier model from file "%s"\' % classifier_filename_exp)\n-        \n-    def classify_image(input_file_path):\n-        np.random.seed(seed=666)\n-        paths = [input_file_path]\n-\n-        # Run forward pass to calculate embeddings\n-        nrof_images = len(paths)\n-        nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / 90))\n-        emb_array = np.zeros((nrof_images, embedding_size))\n-        for i in range(nrof_batches_per_epoch):\n-            start_index = i* 90\n-            end_index = min((i+1) * 90, nrof_images)\n-            paths_batch = paths[start_index:end_index]\n-            images = facenet.load_data(paths_batch, False, False, 160)\n-            feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n-            emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n+        paths_batch = [input_file_path]\n+        images = facenet.load_data(paths_batch, False, False, 160)\n+        feed_dict = { self.images_placeholder:images, self.phase_train_placeholder:False }\n+        emb_array[0:1,:] = self.sess.run(self.embeddings, feed_dict=feed_dict)\n             \n         predictions = model.predict_proba(emb_array)\n         best_class_indices = np.argmax(predictions, axis=1)\n         best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n                     \n-        for i in range(len(best_class_indices)):\n-            print(\'%4d  %s: %.3f\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n-\n-        classifyDictionary = dict()\n-        classifyDictionary["classifyPeopleName"] = class_names[best_class_indices[i]]\n-        classifyDictionary["classifyRate"] = best_class_probabilities[i]\n-        return classifyDictionary\n-            \n+        classify_people_name = class_names[best_class_indices[0]]\n+        classify_rate = best_class_probabilities[0]\n+        return (classify_people_name, classify_rate)\ndiff --git a/device/Main.py b/device/Main.py\nindex c44ac42..075a1a6 100644\n--- a/device/Main.py\n+++ b/device/Main.py\n@@ -5,38 +5,32 @@ import time\n from Camera import Camera\n from OpencvAlign import OpencvAlign\n from requests.auth import HTTPBasicAuth\n+from Model import Model\n \n-payload = {\'equipmentName\': \'\xe5\xae\xb6\xe8\xa3\xa1\xe7\x9a\x84\xe9\x96\x80\', \'email\': "feveraly@gmail.com",\'password\':5566}\n-new_model = requests.post("https://localhost/api/model", json=payload, verify = False)\n-\n-with open("test.pkl", \'wb\') as outfile: \n-    outfile.write(new_model.content)\n-    #reload_model()\n-print("download ok")\n from Classify import * \n \n-test_classifier_path = "./test.pkl"\n+camera = Camera(0)\n+classify_result = (\'unknown\', 0.0)\n+model = Model("feveraly@gmail.com", 5566, \'\xe5\xae\xb6\xe8\xa3\xa1\xe7\x9a\x84\xe9\x96\x80\')\n+classify = Classify()\n \n-count = 0\n-camera = Camera(1)\n-classifyList = {"classifyPeopleName":\'unknown\',"classifyRate":0.0}\n while(True):\n-    frame = camera.CatchImage()\n-    if cv2.waitKey(1) & 0xFF == ord(\'c\'):\n-        start = time.time()\n-        cut = OpencvAlign(frame)\n-        if(cut.Cut()):\n-            cut.Resize()\n-            classifyList = classify_image("./image/cut.png")\n-        end = time.time()\n-        time.sleep(0.1)\n-    classifyPersonName =  classifyList["classifyPeopleName"]\n-    classifyRate =  classifyList["classifyRate"] \n-    cv2.putText(frame,classifyPersonName,(10,40),cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)\n-    cv2.putText(frame,str(classifyRate),(10,80),cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)\n     if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n         break\n-\n-    cv2.imshow("Display window", frame)  \n-    \n-\n+    if cv2.waitKey(1) & 0xFF == ord(\'r\'):\n+        print(\'reloading\')\n+        model.reload_model()\n+        print(\'reloading over\')\n+    if cv2.waitKey(1) & 0xFF == ord(\'c\'):\n+        print(\'c\')\n+        start = time.time()\n+        align = OpencvAlign(frame)\n+        if(align.Cut()):\n+            align.Resize()\n+            classify_result = classify.classify_image("./image/cut.png",model)\n+            end = time.time()\n+            print("cost time", end - start)\n+    frame = camera.CatchImage()\n+    cv2.putText(frame,classify_result[0],(10,40),cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)\n+    cv2.putText(frame,str(classify_result[1]),(10,80),cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 0), 1, cv2.LINE_AA)\n+    cv2.imshow("Display window", frame)  \n\\ No newline at end of file\ndiff --git a/device/Model.py b/device/Model.py\nindex 6ad0004..280520f 100644\n--- a/device/Model.py\n+++ b/device/Model.py\n@@ -1,12 +1,32 @@\n import requests\n+import os\n+import pickle\n \n class Model():\n-    def __init__(user_email,password,equipment_name):\n-      self.user_email = user_email\n-      self.password = password \n-    def update():  \n-        payload = {email:self.user_email,password:self.password,equipment:self.equipment_name}\n+    def __init__(self,user_email,password,equipment_name):\n+        self.user_email = user_email\n+        self.password = password\n+        self.equipment_name = equipment_name\n+        self.model = None\n+        self.class_names = None\n+        self.model_path = "test.pkl"\n+        self.update()\n+\n+    def update(self):  \n+        payload = {\'email\':self.user_email,\'password\':self.password,\'equipmentName\':self.equipment_name}\n         new_model = requests.post("https://localhost/api/model", json=payload, verify = False)\n-        with open("test.pkl", \'wb\') as outfile: \n+        print(new_model)\n+        with open(self.model_path, \'wb\') as outfile: \n             outfile.write(new_model.content)\n-            reload_model()\n\\ No newline at end of file\n+            self.reload_model()\n+\n+    def reload_model(self):\n+        classifier_filename_exp = os.path.expanduser(self.model_path)\n+        infile = open(classifier_filename_exp, \'rb\')\n+        (self.model, self.class_names) = pickle.load(infile)\n+    \n+    def get_model(self):\n+        return self.model\n+\n+    def get_class_names(self):\n+        return self.class_names\ndiff --git a/device/OpencvAlign.py b/device/OpencvAlign.py\nindex 65523db..84ea8ac 100644\n--- a/device/OpencvAlign.py\n+++ b/device/OpencvAlign.py\n@@ -17,7 +17,7 @@ class OpencvAlign:\n             minNeighbors=2,\n             minSize=(30, 30),\n         )\n-        print (\'Found {0} faces!\'.format(len(self.faces)) )\n+        #print (\'Found {0} faces!\'.format(len(self.faces)) )\n \n         if(len(self.faces) > 0):\n             return True\ndiff --git a/device/image/cut.png b/device/image/cut.png\nindex 5d0168b..c765036 100644\nBinary files a/device/image/cut.png and b/device/image/cut.png differ\ndiff --git a/device/models/tom.pkl b/device/models/tom.pkl\nindex eb9a108..594a999 100644\nBinary files a/device/models/tom.pkl and b/device/models/tom.pkl differ\ndiff --git a/device/test.pkl b/device/test.pkl\nindex a4e0dbb..d58a8d7 100644\nBinary files a/device/test.pkl and b/device/test.pkl differ\ndiff --git a/server/.gitignore b/server/.gitignore\nnew file mode 100644\nindex 0000000..f2a723b\n--- /dev/null\n+++ b/server/.gitignore\n@@ -0,0 +1 @@\n+*.pkl\n\\ No newline at end of file\ndiff --git a/server/app.js b/server/app.js\nindex 720219b..1cf3db0 100644\n--- a/server/app.js\n+++ b/server/app.js\n@@ -13,7 +13,6 @@ const certificate = fs.readFileSync(__dirname + \'/ssl/certificate.crt\');\n const credentials = { key: privateKey, cert: certificate }\n \n app.set(\'port\', process.env.PORT || config.httpsPort)\n-\n app.use(bodyParser.urlencoded({ extended: false }));\n app.use(bodyParser.json({ limit: \'50mb\', type: \'application/json\' }));\n app.use(cors({\n@@ -26,11 +25,14 @@ httpApp.get("*", (req, res, next) => {\n   res.redirect("https://" + req.headers.host + req.path)\n })\n \n+\n let passport = require(\'./passport\')(app)\n let routes = require(\'./routes\')(app, passport)\n \n app.use(history()) // This line must be added below routes , not above\n app.use(express.static(\'../client/dist\'))\n \n-http.createServer(httpApp).listen(httpApp.get(\'port\'), () => {})\n-https.createServer(credentials, app).listen(app.get(\'port\'), () => {})\n+app.get(\'/test\', ()=> res.send(\'112233\'))\n+\n+http.createServer(httpApp).listen(httpApp.get(\'port\'), () => console.log(`HTTP Server listen on port ${httpApp.get(\'port\')}`))\n+https.createServer(credentials, app).listen(app.get(\'port\'), () => console.log(`HTTPS Server listen on port ${app.get(\'port\')}`))\ndiff --git a/server/controllers/ImageController.js b/server/controllers/ImageController.js\nindex 0e4c2da..e61ca7f 100644\n--- a/server/controllers/ImageController.js\n+++ b/server/controllers/ImageController.js\n@@ -7,9 +7,9 @@ const FaceBelongModel = require(\'../models/FaceBelongModel\')\n const request = require(\'request\');\n const Model = require(\'../models/Model\')\n \n-const uploadBasePath = `${process.cwd()}/facenetTrain/image/raw`\n-const cutBasePath = `${process.cwd()}/facenetTrain/image/cut`\n-const modelBasePath = `${process.cwd()}/facenetTrain/models`\n+const uploadBasePath = `${process.cwd()}/faceAlign/image/raw`\n+const cutBasePath = `${process.cwd()}/faceAlign/image/cut`\n+const modelBasePath = `${process.cwd()}/faceAlign/models`\n \n module.exports = { \n \ndiff --git a/server/controllers/ModelController.js b/server/controllers/ModelController.js\nindex 0938712..d8eb0c4 100644\n--- a/server/controllers/ModelController.js\n+++ b/server/controllers/ModelController.js\n@@ -19,7 +19,7 @@ module.exports = {\n     }\n     const equipmentId = await Equipment.FindIdByOwnerEmailAndName(userEmail,equipmentName)\n     const modelId = await Equipment.FindModelIdByEquipmentId(equipmentId)\n-    fs.readFile(`./facenetTrain/models/${modelId}.pkl`, (err, data) => {\n+    fs.readFile(`./faceAlign/models/${modelId}.pkl`, (err, data) => {\n       res.send(data)\n     })\n   },\ndiff --git a/server/database/InitialDatabase.js b/server/database/InitialDatabase.js\nindex 8d6bebe..d4c06c0 100644\n--- a/server/database/InitialDatabase.js\n+++ b/server/database/InitialDatabase.js\n@@ -93,17 +93,17 @@ if (!require(\'fs\').existsSync(\'facenetTrain/models\')) {\n \n require(\'fs\').readdir(\'facenetTrain/image/raw\', (err, files) => {\n   for(let i = 0 ; i < files.length ; i++)\n-    require(\'rimraf\')(`facenetTrain/image/raw/${files[i]}`,()=>{})\n+    require(\'rimraf\')(`faceAlign/image/raw/${files[i]}`,()=>{})\n })\n \n require(\'fs\').readdir(\'facenetTrain/image/cut\', (err, files) => {\n   for(let i = 0 ; i < files.length ; i++)\n-    require(\'rimraf\')(`facenetTrain/image/cut/${files[i]}`,()=>{})\n+    require(\'rimraf\')(`faceAlign/image/cut/${files[i]}`,()=>{})\n })\n \n require(\'fs\').readdir(\'facenetTrain/models\', (err, files) => {\n   for(let i = 0 ; i < files.length ; i++)\n-    require(\'rimraf\')(`facenetTrain/models/${files[i]}`,()=>{})\n+    require(\'rimraf\')(`faceAlign/models/${files[i]}`,()=>{})\n })\n \n console.log(\'Finished Initial database and image folder\')\n\\ No newline at end of file\ndiff --git a/server/faceAlign/app.py b/server/faceAlign/app.py\nindex 5a79270..661f007 100644\n--- a/server/faceAlign/app.py\n+++ b/server/faceAlign/app.py\n@@ -10,6 +10,8 @@ from utility.blurr import *\n import logging\n import requests\n import json\n+import urllib3\n+urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n \n app = Flask(__name__)\n cutPicture = CutPicture(); \n@@ -32,9 +34,9 @@ def TrainModel():\n                                                                                     verify = False)\n             train.PopOldestData()\n \n-t = threading.Thread(target=TrainModel)\n-t.setDaemon(True)\n-t.start()\n+thread = threading.Thread(target=TrainModel)\n+thread.setDaemon(True)\n+thread.start()\n \n @app.route(\'/align\', methods=[\'POST\'])\n def alignPicture():\ndiff --git a/server/faceAlign/utility/Train.py b/server/faceAlign/utility/Train.py\nindex 5c2af0f..cb1e44a 100644\n--- a/server/faceAlign/utility/Train.py\n+++ b/server/faceAlign/utility/Train.py\n@@ -1,27 +1,3 @@\n-"""An example of how to use your own dataset to train a classifier that recognizes people.\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n@@ -40,8 +16,8 @@ from sklearn.svm import SVC\n batch_size = 1000\n nrof_images = 1\n image_size = 160\n-model_path = "./facenetTrain/20170512-110547.pb"\n-unknown_path = "./facenetTrain/image/unknown"\n+model_path = "./faceAlign/models/20170512-110547.pb"\n+unknown_path = "./faceAlign/image/unknown"\n \n class Train:\n     def __init__(self):\n@@ -50,32 +26,21 @@ class Train:\n     def trainModel(self, DirList, input_dir, output_dir, faceIdNamePairs):\n         self.specificDirList = DirList\n         with tf.Graph().as_default():\n-        \n             with tf.Session() as sess:\n-                \n                 np.random.seed(seed=666)\n                 dataset = self.get_dataset(input_dir,self.specificDirList,faceIdNamePairs)\n \n-                # Check that there are at least one training image per class\n                 for cls in dataset:\n                     assert(len(cls.image_paths)>0, \'There must be at least one image for each class in the dataset\')            \n \n                 paths, labels = facenet.get_image_paths_and_labels(dataset)\n-                # print(\'Number of classes: %d\' % len(dataset))\n-                # print(\'Number of images: %d\' % len(paths))\n-                \n-                # Load the model\n-                # print(\'Loading feature extraction model\')\n                 facenet.load_model(model_path)\n                 \n-                # Get input and output tensors\n                 images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n                 embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n                 phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n                 embedding_size = embeddings.get_shape()[1]\n                 \n-                # Run forward pass to calculate embeddings\n-                # print(\'Calculating features for images\')\n                 nrof_images = len(paths)\n                 nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n                 emb_array = np.zeros((nrof_images, embedding_size))\n@@ -89,15 +54,11 @@ class Train:\n                 \n                 classifier_filename_exp = os.path.expanduser(output_dir)\n \n-                # Train classifier\n-                # print(\'Training classifier\')\n                 model = SVC(kernel=\'linear\', probability=True)\n                 model.fit(emb_array, labels)\n             \n-                # Create a list of class names\n                 class_names = [ cls.name.replace(\'_\', \' \') for cls in dataset]\n \n-                # Saving classifier model\n                 with open(classifier_filename_exp, \'wb\') as outfile:\n                     pickle.dump((model, class_names), outfile)\n                 print(\'-----------------Saved classifier model to file "%s"\' % classifier_filename_exp)\ndiff --git a/server/facenetTrain/models/c96a14b4d57e4fc17a98802f47da1797.pkl b/server/facenetTrain/models/c96a14b4d57e4fc17a98802f47da1797.pkl\ndeleted file mode 100644\nindex 704eea5..0000000\nBinary files a/server/facenetTrain/models/c96a14b4d57e4fc17a98802f47da1797.pkl and /dev/null differ\ndiff --git a/server/routes.js b/server/routes.js\nindex 1470a28..ab3620e 100644\n--- a/server/routes.js\n+++ b/server/routes.js\n@@ -34,7 +34,6 @@ module.exports = (app, passport) => {\n     modelRouter.post(\'/notify\',ModelController.NotifyTrainFinish)\n     modelRouter.post(\'/check\',ModelController.CheckModelIsTrain)\n \n-\n     app.use(\'/api/authentication\', AuthenticationRouter)\n     app.use(\'/api/equipment\', equipmentRouter)\n     app.use(\'/api/face\', faceRouter)'